{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 519.5MB 114kB/s eta 0:00:01   16% |█████▎                          | 85.6MB 43.1MB/s eta 0:00:11    64% |████████████████████▌           | 333.2MB 56.0MB/s eta 0:00:04\n",
      "\u001b[?25hCollecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 30.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from torchvision) (5.2.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from torchvision) (1.14.5)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-0.4.1 torchvision-0.2.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘train’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir train\n",
    "!mkdir tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "from scipy import sparse as sp\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pref_data = sp.load_npz(\"pref.npz\")\n",
    "#conf_data = sp.load_npz(\"confi.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_coo = pref_data.tocoo(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'userID': data_coo.row, 'itemID': data_coo.col, 'rating': data_coo.data})[['userID', 'itemID', 'rating']] \\\n",
    ".reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[userID    0\n",
       " itemID    0\n",
       " rating    1\n",
       " Name: 0, dtype: int64, userID    0\n",
       " itemID    0\n",
       " rating    1\n",
       " Name: 0, dtype: int64, userID    0\n",
       " itemID    0\n",
       " rating    1\n",
       " Name: 0, dtype: int64, [0, 0, 1], [0, 0, 1]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _, row in df.iterrows():\n",
    "    a.append([row[0],row[1],row[2]])\n",
    "    break\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "1090000\n",
      "1100000\n",
      "1110000\n",
      "1120000\n",
      "1130000\n",
      "1140000\n",
      "1150000\n",
      "1160000\n",
      "1170000\n",
      "1180000\n",
      "1190000\n",
      "1200000\n",
      "1210000\n",
      "1220000\n",
      "1230000\n",
      "1240000\n",
      "1250000\n",
      "1260000\n",
      "1270000\n",
      "1280000\n",
      "1290000\n",
      "1300000\n",
      "1310000\n",
      "1320000\n",
      "1330000\n",
      "1340000\n",
      "1350000\n",
      "1360000\n",
      "1370000\n",
      "1380000\n",
      "1390000\n",
      "1400000\n",
      "1410000\n",
      "1420000\n",
      "1430000\n",
      "1440000\n",
      "1450000\n",
      "1460000\n",
      "1470000\n",
      "1480000\n",
      "1490000\n",
      "1500000\n",
      "1510000\n",
      "1520000\n",
      "1530000\n",
      "1540000\n",
      "1550000\n",
      "1560000\n",
      "1570000\n",
      "1580000\n",
      "1590000\n",
      "1600000\n",
      "1610000\n",
      "1620000\n",
      "1630000\n",
      "1640000\n",
      "1650000\n",
      "1660000\n",
      "1670000\n",
      "1680000\n",
      "1690000\n",
      "1700000\n",
      "1710000\n",
      "1720000\n",
      "1730000\n",
      "1740000\n",
      "1750000\n",
      "1760000\n",
      "1770000\n",
      "1780000\n",
      "1790000\n",
      "1800000\n",
      "1810000\n",
      "1820000\n",
      "1830000\n",
      "1840000\n",
      "1850000\n",
      "1860000\n",
      "1870000\n",
      "1880000\n",
      "1890000\n",
      "1900000\n",
      "1910000\n",
      "1920000\n",
      "1930000\n",
      "1940000\n",
      "1950000\n",
      "1960000\n",
      "1970000\n",
      "1980000\n",
      "1990000\n",
      "2000000\n",
      "2010000\n",
      "2020000\n",
      "2030000\n",
      "2040000\n",
      "2050000\n",
      "2060000\n",
      "2070000\n",
      "2080000\n",
      "2090000\n",
      "2100000\n",
      "2110000\n",
      "2120000\n",
      "2130000\n",
      "2140000\n",
      "2150000\n",
      "2160000\n",
      "2170000\n",
      "2180000\n",
      "2190000\n",
      "2200000\n",
      "2210000\n",
      "2220000\n",
      "2230000\n",
      "2240000\n",
      "2250000\n",
      "2260000\n",
      "2270000\n",
      "2280000\n",
      "2290000\n",
      "2300000\n",
      "2310000\n",
      "2320000\n",
      "2330000\n",
      "2340000\n",
      "2350000\n",
      "2360000\n",
      "2370000\n",
      "2380000\n",
      "2390000\n",
      "2400000\n",
      "2410000\n",
      "2420000\n",
      "2430000\n",
      "2440000\n",
      "2450000\n",
      "2460000\n",
      "2470000\n",
      "2480000\n",
      "2490000\n",
      "2500000\n",
      "2510000\n",
      "2520000\n",
      "2530000\n",
      "2540000\n",
      "2550000\n",
      "2560000\n",
      "2570000\n",
      "2580000\n",
      "2590000\n",
      "2600000\n",
      "2610000\n",
      "2620000\n",
      "2630000\n",
      "2640000\n",
      "2650000\n",
      "2660000\n",
      "2670000\n",
      "2680000\n",
      "2690000\n",
      "2700000\n",
      "2710000\n",
      "2720000\n",
      "2730000\n",
      "2740000\n",
      "2750000\n",
      "2760000\n",
      "2770000\n",
      "2780000\n",
      "2790000\n",
      "2800000\n",
      "2810000\n",
      "2820000\n",
      "2830000\n",
      "2840000\n",
      "2850000\n",
      "2860000\n",
      "2870000\n",
      "2880000\n",
      "2890000\n",
      "2900000\n",
      "2910000\n",
      "2920000\n",
      "2930000\n",
      "2940000\n",
      "2950000\n",
      "2960000\n",
      "2970000\n",
      "2980000\n",
      "2990000\n",
      "3000000\n",
      "3010000\n",
      "3020000\n",
      "3030000\n",
      "3040000\n",
      "3050000\n",
      "3060000\n",
      "3070000\n",
      "3080000\n",
      "3090000\n",
      "3100000\n",
      "3110000\n",
      "3120000\n",
      "3130000\n",
      "3140000\n",
      "3150000\n",
      "3160000\n",
      "3170000\n",
      "3180000\n",
      "3190000\n",
      "3200000\n",
      "3210000\n",
      "3220000\n",
      "3230000\n",
      "3240000\n",
      "3250000\n",
      "3260000\n",
      "3270000\n",
      "3280000\n",
      "3290000\n",
      "3300000\n",
      "3310000\n",
      "3320000\n",
      "3330000\n",
      "3340000\n",
      "3350000\n",
      "3360000\n",
      "3370000\n",
      "3380000\n",
      "3390000\n",
      "3400000\n",
      "3410000\n",
      "3420000\n",
      "3430000\n",
      "3440000\n",
      "3450000\n",
      "3460000\n",
      "3470000\n",
      "3480000\n",
      "3490000\n",
      "3500000\n",
      "3510000\n",
      "3520000\n",
      "3530000\n",
      "3540000\n",
      "3550000\n",
      "3560000\n",
      "3570000\n",
      "3580000\n",
      "3590000\n",
      "3600000\n",
      "3610000\n",
      "3620000\n",
      "3630000\n",
      "3640000\n",
      "3650000\n",
      "3660000\n",
      "3670000\n",
      "3680000\n",
      "3690000\n",
      "3700000\n",
      "3710000\n",
      "3720000\n",
      "3730000\n",
      "3740000\n",
      "3750000\n",
      "3760000\n",
      "3770000\n",
      "3780000\n",
      "3790000\n",
      "3800000\n",
      "3810000\n",
      "3820000\n",
      "3830000\n",
      "3840000\n",
      "3850000\n",
      "3860000\n",
      "3870000\n",
      "3880000\n",
      "3890000\n",
      "3900000\n",
      "3910000\n",
      "3920000\n",
      "3930000\n",
      "3940000\n",
      "3950000\n",
      "3960000\n",
      "3970000\n",
      "3980000\n",
      "3990000\n",
      "4000000\n",
      "4010000\n",
      "4020000\n",
      "4030000\n",
      "4040000\n",
      "4050000\n",
      "4060000\n",
      "4070000\n",
      "4080000\n",
      "4090000\n",
      "4100000\n",
      "4110000\n",
      "4120000\n",
      "4130000\n",
      "4140000\n",
      "4150000\n",
      "4160000\n",
      "4170000\n",
      "4180000\n",
      "4190000\n",
      "4200000\n",
      "4210000\n",
      "4220000\n",
      "4230000\n",
      "4240000\n",
      "4250000\n",
      "4260000\n",
      "4270000\n",
      "4280000\n",
      "4290000\n",
      "4300000\n",
      "4310000\n",
      "4320000\n",
      "4330000\n",
      "4340000\n",
      "4350000\n",
      "4360000\n",
      "4370000\n",
      "4380000\n",
      "4390000\n",
      "4400000\n",
      "4410000\n",
      "4420000\n",
      "4430000\n",
      "4440000\n",
      "4450000\n",
      "4460000\n",
      "4470000\n",
      "4480000\n",
      "4490000\n",
      "4500000\n",
      "4510000\n",
      "4520000\n",
      "4530000\n",
      "4540000\n",
      "4550000\n",
      "4560000\n",
      "4570000\n",
      "4580000\n",
      "4590000\n",
      "4600000\n",
      "4610000\n",
      "4620000\n",
      "4630000\n",
      "4640000\n",
      "4650000\n",
      "4660000\n",
      "4670000\n",
      "4680000\n",
      "4690000\n",
      "4700000\n",
      "4710000\n",
      "4720000\n",
      "4730000\n",
      "4740000\n",
      "4750000\n",
      "4760000\n",
      "4770000\n",
      "4780000\n",
      "4790000\n",
      "4800000\n",
      "4810000\n",
      "4820000\n",
      "4830000\n",
      "4840000\n",
      "4850000\n",
      "4860000\n",
      "4870000\n",
      "4880000\n",
      "4890000\n",
      "4900000\n",
      "4910000\n",
      "4920000\n",
      "4930000\n",
      "4940000\n",
      "4950000\n",
      "4960000\n",
      "4970000\n",
      "4980000\n",
      "4990000\n",
      "5000000\n",
      "5010000\n",
      "5020000\n",
      "5030000\n",
      "5040000\n",
      "5050000\n",
      "5060000\n",
      "5070000\n",
      "5080000\n",
      "5090000\n",
      "5100000\n",
      "5110000\n",
      "5120000\n",
      "5130000\n",
      "5140000\n",
      "5150000\n",
      "5160000\n",
      "5170000\n",
      "5180000\n",
      "5190000\n",
      "5200000\n",
      "5210000\n",
      "5220000\n",
      "5230000\n",
      "5240000\n",
      "5250000\n",
      "5260000\n",
      "5270000\n",
      "5280000\n",
      "5290000\n",
      "5300000\n",
      "5310000\n",
      "5320000\n",
      "5330000\n",
      "5340000\n",
      "5350000\n",
      "5360000\n",
      "5370000\n",
      "5380000\n",
      "5390000\n",
      "5400000\n",
      "5410000\n",
      "5420000\n",
      "5430000\n",
      "5440000\n",
      "5450000\n",
      "5460000\n",
      "5470000\n",
      "5480000\n",
      "5490000\n",
      "5500000\n",
      "5510000\n",
      "5520000\n",
      "5530000\n",
      "5540000\n",
      "5550000\n",
      "5560000\n",
      "5570000\n",
      "5580000\n",
      "5590000\n",
      "5600000\n",
      "5610000\n",
      "5620000\n",
      "5630000\n",
      "5640000\n",
      "5650000\n",
      "5660000\n",
      "5670000\n",
      "5680000\n",
      "5690000\n",
      "5700000\n",
      "5710000\n",
      "5720000\n",
      "5730000\n",
      "5740000\n",
      "5750000\n",
      "5760000\n",
      "5770000\n",
      "5780000\n",
      "5790000\n",
      "5800000\n",
      "5810000\n",
      "5820000\n",
      "5830000\n",
      "5840000\n",
      "5850000\n",
      "5860000\n",
      "5870000\n",
      "5880000\n",
      "5890000\n",
      "5900000\n",
      "5910000\n",
      "5920000\n",
      "5930000\n",
      "5940000\n",
      "5950000\n",
      "5960000\n",
      "5970000\n",
      "5980000\n",
      "5990000\n",
      "6000000\n",
      "6010000\n",
      "6020000\n",
      "6030000\n",
      "6040000\n",
      "6050000\n",
      "6060000\n",
      "6070000\n",
      "6080000\n",
      "6090000\n",
      "6100000\n",
      "6110000\n",
      "6120000\n",
      "6130000\n",
      "6140000\n",
      "6150000\n",
      "6160000\n",
      "6170000\n",
      "6180000\n",
      "6190000\n",
      "6200000\n",
      "6210000\n",
      "6220000\n",
      "6230000\n",
      "6240000\n",
      "6250000\n",
      "6260000\n",
      "6270000\n",
      "6280000\n",
      "6290000\n",
      "6300000\n",
      "6310000\n",
      "6320000\n",
      "6330000\n",
      "6340000\n",
      "6350000\n",
      "6360000\n",
      "6370000\n",
      "6380000\n",
      "6390000\n",
      "6400000\n",
      "6410000\n",
      "6420000\n",
      "6430000\n",
      "6440000\n",
      "6450000\n",
      "6460000\n",
      "6470000\n",
      "6480000\n",
      "6490000\n",
      "6500000\n",
      "6510000\n",
      "6520000\n",
      "6530000\n",
      "6540000\n",
      "6550000\n",
      "6560000\n",
      "6570000\n",
      "6580000\n",
      "6590000\n",
      "6600000\n",
      "6610000\n",
      "6620000\n",
      "6630000\n",
      "6640000\n",
      "6650000\n",
      "6660000\n",
      "6670000\n",
      "6680000\n",
      "6690000\n",
      "6700000\n",
      "6710000\n",
      "6720000\n",
      "6730000\n",
      "6740000\n",
      "6750000\n",
      "6760000\n",
      "6770000\n",
      "6780000\n",
      "6790000\n",
      "6800000\n",
      "6810000\n",
      "6820000\n",
      "6830000\n",
      "6840000\n",
      "6850000\n",
      "6860000\n",
      "6870000\n",
      "6880000\n",
      "6890000\n",
      "6900000\n",
      "6910000\n",
      "6920000\n",
      "6930000\n",
      "6940000\n",
      "6950000\n",
      "6960000\n",
      "6970000\n",
      "6980000\n",
      "6990000\n",
      "7000000\n",
      "7010000\n",
      "7020000\n",
      "7030000\n",
      "7040000\n",
      "7050000\n",
      "7060000\n",
      "7070000\n",
      "7080000\n",
      "7090000\n",
      "7100000\n",
      "7110000\n",
      "7120000\n",
      "7130000\n",
      "7140000\n",
      "7150000\n",
      "7160000\n",
      "7170000\n",
      "7180000\n",
      "7190000\n",
      "7200000\n",
      "7210000\n",
      "7220000\n",
      "7230000\n",
      "7240000\n",
      "7250000\n",
      "7260000\n",
      "7270000\n",
      "7280000\n",
      "7290000\n",
      "7300000\n",
      "7310000\n",
      "7320000\n",
      "7330000\n",
      "7340000\n",
      "7350000\n",
      "7360000\n",
      "7370000\n",
      "7380000\n",
      "7390000\n",
      "7400000\n",
      "7410000\n",
      "7420000\n",
      "7430000\n",
      "7440000\n",
      "7450000\n",
      "7460000\n",
      "7470000\n",
      "7480000\n",
      "7490000\n",
      "7500000\n",
      "7510000\n",
      "7520000\n",
      "7530000\n",
      "7540000\n",
      "7550000\n",
      "7560000\n",
      "7570000\n",
      "7580000\n",
      "7590000\n",
      "7600000\n",
      "7610000\n",
      "7620000\n",
      "7630000\n",
      "7640000\n",
      "7650000\n",
      "7660000\n",
      "7670000\n",
      "7680000\n",
      "7690000\n",
      "7700000\n",
      "7710000\n",
      "7720000\n",
      "7730000\n",
      "7740000\n",
      "7750000\n",
      "7760000\n",
      "7770000\n",
      "7780000\n",
      "7790000\n",
      "7800000\n",
      "7810000\n",
      "7820000\n",
      "7830000\n",
      "7840000\n",
      "7850000\n",
      "7860000\n",
      "7870000\n",
      "7880000\n",
      "7890000\n",
      "7900000\n",
      "7910000\n",
      "7920000\n",
      "7930000\n",
      "7940000\n",
      "7950000\n",
      "7960000\n",
      "7970000\n",
      "7980000\n",
      "7990000\n",
      "8000000\n",
      "8010000\n",
      "8020000\n",
      "8030000\n",
      "8040000\n",
      "8050000\n",
      "8060000\n",
      "8070000\n",
      "8080000\n",
      "8090000\n",
      "8100000\n",
      "8110000\n",
      "8120000\n",
      "8130000\n",
      "8140000\n",
      "8150000\n",
      "8160000\n",
      "8170000\n",
      "8180000\n",
      "8190000\n",
      "8200000\n",
      "8210000\n",
      "8220000\n",
      "8230000\n",
      "8240000\n",
      "8250000\n",
      "8260000\n",
      "8270000\n",
      "8280000\n",
      "8290000\n",
      "8300000\n",
      "8310000\n",
      "8320000\n",
      "8330000\n",
      "8340000\n",
      "8350000\n",
      "8360000\n",
      "8370000\n",
      "8380000\n",
      "8390000\n",
      "8400000\n",
      "8410000\n",
      "8420000\n",
      "8430000\n",
      "8440000\n",
      "8450000\n",
      "8460000\n",
      "8470000\n",
      "8480000\n",
      "8490000\n",
      "8500000\n",
      "8510000\n",
      "8520000\n",
      "8530000\n",
      "8540000\n",
      "8550000\n",
      "8560000\n",
      "8570000\n",
      "8580000\n",
      "8590000\n",
      "8600000\n",
      "8610000\n",
      "8620000\n",
      "8630000\n",
      "8640000\n",
      "8650000\n",
      "8660000\n",
      "8670000\n",
      "8680000\n",
      "8690000\n",
      "8700000\n",
      "8710000\n",
      "8720000\n",
      "8730000\n",
      "8740000\n",
      "8750000\n",
      "8760000\n",
      "8770000\n",
      "8780000\n",
      "8790000\n",
      "8800000\n",
      "8810000\n",
      "8820000\n",
      "8830000\n",
      "8840000\n",
      "8850000\n",
      "8860000\n",
      "8870000\n",
      "8880000\n",
      "8890000\n",
      "8900000\n",
      "8910000\n",
      "8920000\n",
      "8930000\n",
      "8940000\n",
      "8950000\n",
      "8960000\n",
      "8970000\n",
      "8980000\n",
      "8990000\n",
      "9000000\n",
      "9010000\n",
      "9020000\n",
      "9030000\n",
      "9040000\n",
      "9050000\n",
      "9060000\n",
      "9070000\n",
      "9080000\n",
      "9090000\n",
      "9100000\n",
      "9110000\n",
      "9120000\n",
      "9130000\n",
      "9140000\n",
      "9150000\n",
      "9160000\n",
      "9170000\n",
      "9180000\n",
      "9190000\n",
      "9200000\n",
      "9210000\n",
      "9220000\n",
      "9230000\n",
      "9240000\n",
      "9250000\n",
      "9260000\n",
      "9270000\n",
      "9280000\n",
      "9290000\n",
      "9300000\n",
      "9310000\n",
      "9320000\n",
      "9330000\n",
      "9340000\n",
      "9350000\n",
      "9360000\n",
      "9370000\n",
      "9380000\n",
      "9390000\n",
      "9400000\n",
      "9410000\n",
      "9420000\n",
      "9430000\n",
      "9440000\n",
      "9450000\n",
      "9460000\n",
      "9470000\n",
      "9480000\n",
      "9490000\n",
      "9500000\n",
      "9510000\n",
      "9520000\n",
      "9530000\n",
      "9540000\n",
      "9550000\n",
      "9560000\n",
      "9570000\n",
      "9580000\n",
      "9590000\n",
      "9600000\n",
      "9610000\n",
      "9620000\n",
      "9630000\n",
      "9640000\n",
      "9650000\n",
      "9660000\n",
      "9670000\n",
      "9680000\n",
      "9690000\n",
      "9700000\n",
      "9710000\n",
      "9720000\n",
      "9730000\n",
      "9740000\n",
      "9750000\n",
      "9760000\n",
      "9770000\n",
      "9780000\n",
      "9790000\n",
      "9800000\n",
      "9810000\n",
      "9820000\n",
      "9830000\n",
      "9840000\n",
      "9850000\n",
      "9860000\n",
      "9870000\n",
      "9880000\n",
      "9890000\n",
      "9900000\n",
      "9910000\n",
      "9920000\n",
      "9930000\n",
      "9940000\n",
      "9950000\n",
      "9960000\n",
      "9970000\n",
      "9980000\n",
      "9990000\n",
      "10000000\n",
      "10010000\n",
      "10020000\n",
      "10030000\n",
      "10040000\n",
      "10050000\n",
      "10060000\n",
      "10070000\n",
      "10080000\n",
      "10090000\n",
      "10100000\n",
      "10110000\n",
      "10120000\n",
      "10130000\n",
      "10140000\n",
      "10150000\n",
      "10160000\n",
      "10170000\n",
      "10180000\n",
      "10190000\n",
      "10200000\n",
      "10210000\n",
      "10220000\n",
      "10230000\n",
      "10240000\n",
      "10250000\n",
      "10260000\n",
      "10270000\n",
      "10280000\n",
      "10290000\n",
      "10300000\n",
      "10310000\n",
      "10320000\n",
      "10330000\n",
      "10340000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10350000\n",
      "10360000\n",
      "10370000\n",
      "10380000\n",
      "10390000\n",
      "10400000\n",
      "10410000\n",
      "10420000\n",
      "10430000\n",
      "10440000\n",
      "10450000\n",
      "10460000\n",
      "10470000\n",
      "10480000\n",
      "10490000\n",
      "10500000\n",
      "10510000\n",
      "10520000\n",
      "10530000\n",
      "10540000\n",
      "10550000\n",
      "10560000\n",
      "10570000\n",
      "10580000\n",
      "10590000\n",
      "10600000\n",
      "10610000\n",
      "10620000\n",
      "10630000\n",
      "10640000\n",
      "10650000\n",
      "10660000\n",
      "10670000\n",
      "10680000\n",
      "10690000\n",
      "10700000\n",
      "10710000\n",
      "10720000\n",
      "10730000\n",
      "10740000\n",
      "10750000\n",
      "10760000\n",
      "10770000\n",
      "10780000\n",
      "10790000\n",
      "10800000\n",
      "10810000\n",
      "10820000\n",
      "10830000\n",
      "10840000\n",
      "10850000\n",
      "10860000\n",
      "10870000\n",
      "10880000\n",
      "10890000\n",
      "10900000\n",
      "10910000\n",
      "10920000\n",
      "10930000\n",
      "10940000\n",
      "10950000\n",
      "10960000\n",
      "10970000\n",
      "10980000\n",
      "10990000\n",
      "11000000\n",
      "11010000\n",
      "11020000\n",
      "11030000\n",
      "11040000\n",
      "11050000\n",
      "11060000\n",
      "11070000\n",
      "11080000\n",
      "11090000\n",
      "11100000\n",
      "11110000\n",
      "11120000\n",
      "11130000\n",
      "11140000\n",
      "11150000\n",
      "11160000\n",
      "11170000\n",
      "11180000\n",
      "11190000\n",
      "11200000\n",
      "11210000\n",
      "11220000\n",
      "11230000\n",
      "11240000\n"
     ]
    }
   ],
   "source": [
    "list_data = [[0,-1] for i in range(146976)]\n",
    "for index, row in df.iterrows():\n",
    "    list_data[row[0]][0]+=1\n",
    "    list_data[row[0]][1] = index\n",
    "    if(index%10000 ==0):\n",
    "        print(index)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15108\n"
     ]
    }
   ],
   "source": [
    "for i in range(146976):\n",
    "    if list_data[i][0] == 0:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID    146975\n",
       "itemID      4225\n",
       "rating         0\n",
       "Name: 11248214, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = len(df)\n",
    "add_data = []\n",
    "for x in list_data:\n",
    "    if x[0]==1:\n",
    "        add_data.append(df.iloc[x[1]])\n",
    "        cnt+=1\n",
    "\n",
    "df=df.append(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID    118759\n",
       "itemID      3195\n",
       "rating         1\n",
       "Name: 9396852, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2,stratify=df[['userID']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID    50199\n",
       "itemID     1349\n",
       "rating        1\n",
       "Name: 6731757, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train.txt\", sep='\\t', index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"test.txt\", sep='\\t', index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv train.txt ./train\n",
    "!mv test.txt ./tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(aug_step=1, batch_size=128, constrained=False, drop_prob=0.8, gpu_ids='0', hidden_layers='512,512,1024', logdir='model_save', lr=0.005, noise_prob=0.0, non_linearity_type='selu', num_epochs=12, optimizer='momentum', path_to_eval_data='tests', path_to_train_data='train', save_every=3, skip_last_layer_nl=False, summary_frequency=1000, weight_decay=0.0)\n",
      "GPU is available.\n",
      "Loading training data\n",
      "146644\n",
      "Data loaded\n",
      "Total items found: 146644\n",
      "Vector dim: 4431\n",
      "Loading eval data\n",
      "/home/ubuntu/DeepRecommender-master/reco_encoder/model/model.py:60: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  weight_init.xavier_uniform(w)\n",
      "/home/ubuntu/DeepRecommender-master/reco_encoder/model/model.py:72: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  weight_init.xavier_uniform(w)\n",
      "******************************\n",
      "******************************\n",
      "[4431, 512, 512, 1024]\n",
      "Dropout drop probability: 0.8\n",
      "Encoder pass:\n",
      "torch.Size([512, 4431])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([1024, 512])\n",
      "torch.Size([1024])\n",
      "Decoder pass:\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4431, 512])\n",
      "torch.Size([4431])\n",
      "******************************\n",
      "******************************\n",
      "######################################################\n",
      "######################################################\n",
      "############# AutoEncoder Model: #####################\n",
      "AutoEncoder(\n",
      "  (drop): Dropout(p=0.8)\n",
      "  (encode_w): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 512x4431]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 512x512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 1024x512]\n",
      "  )\n",
      "  (encode_b): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 512]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 1024]\n",
      "  )\n",
      "  (decode_w): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 512x1024]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 512x512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 4431x512]\n",
      "  )\n",
      "  (decode_b): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 512]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 4431]\n",
      "  )\n",
      ")\n",
      "######################################################\n",
      "######################################################\n",
      "Using GPUs: [0]\n",
      "Doing epoch 0 of 12\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "run.py:198: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  t_loss += loss.data[0]\n",
      "[0,     0] RMSE: 1.2158439\n",
      "run.py:212: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  total_epoch_loss += loss.data[0]\n",
      "[0,  1000] RMSE: 0.4035826\n",
      "Total epoch 0 finished in 18.608919382095337 seconds with TRAINING RMSE loss: 0.38433845160176033\n",
      "run.py:74: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  total_epoch_loss += loss.data[0]\n",
      "run.py:75: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  denom += num_ratings.data[0]\n",
      "Epoch 0 EVALUATION LOSS: 0.08789442636958222\n",
      "Saving model to model_save/model.epoch_0\n",
      "Doing epoch 1 of 12\n",
      "[1,     0] RMSE: 0.1820169\n",
      "[1,  1000] RMSE: 0.1555104\n",
      "Total epoch 1 finished in 18.29349637031555 seconds with TRAINING RMSE loss: 0.1533431078736267\n",
      "Doing epoch 2 of 12\n",
      "[2,     0] RMSE: 0.1372328\n",
      "[2,  1000] RMSE: 0.1249849\n",
      "Total epoch 2 finished in 18.086013555526733 seconds with TRAINING RMSE loss: 0.12400719018079574\n",
      "Doing epoch 3 of 12\n",
      "[3,     0] RMSE: 0.1168926\n",
      "[3,  1000] RMSE: 0.1076896\n",
      "Total epoch 3 finished in 18.177277088165283 seconds with TRAINING RMSE loss: 0.10689151057766048\n",
      "Epoch 3 EVALUATION LOSS: 0.04918938510110774\n",
      "Saving model to model_save/model.epoch_3\n",
      "Doing epoch 4 of 12\n",
      "[4,     0] RMSE: 0.1011383\n",
      "[4,  1000] RMSE: 0.0960080\n",
      "Total epoch 4 finished in 18.259451389312744 seconds with TRAINING RMSE loss: 0.09539945751323096\n",
      "Doing epoch 5 of 12\n",
      "[5,     0] RMSE: 0.0910358\n",
      "[5,  1000] RMSE: 0.0873009\n",
      "Total epoch 5 finished in 18.314358711242676 seconds with TRAINING RMSE loss: 0.08684825549015235\n",
      "Doing epoch 6 of 12\n",
      "[6,     0] RMSE: 0.0835903\n",
      "[6,  1000] RMSE: 0.0806150\n",
      "Total epoch 6 finished in 17.853742599487305 seconds with TRAINING RMSE loss: 0.08021676750189069\n",
      "Epoch 6 EVALUATION LOSS: 0.0365316905040182\n",
      "Saving model to model_save/model.epoch_6\n",
      "Doing epoch 7 of 12\n",
      "[7,     0] RMSE: 0.0774226\n",
      "[7,  1000] RMSE: 0.0751059\n",
      "Total epoch 7 finished in 18.881934881210327 seconds with TRAINING RMSE loss: 0.07480173092669092\n",
      "Doing epoch 8 of 12\n",
      "[8,     0] RMSE: 0.0727079\n",
      "[8,  1000] RMSE: 0.0708325\n",
      "Total epoch 8 finished in 18.597010850906372 seconds with TRAINING RMSE loss: 0.07049408617900861\n",
      "Doing epoch 9 of 12\n",
      "[9,     0] RMSE: 0.0680235\n",
      "[9,  1000] RMSE: 0.0670358\n",
      "Total epoch 9 finished in 17.910934686660767 seconds with TRAINING RMSE loss: 0.06688018631098624\n",
      "Epoch 9 EVALUATION LOSS: 0.029467107003615958\n",
      "Saving model to model_save/model.epoch_9\n",
      "Doing epoch 10 of 12\n",
      "[10,     0] RMSE: 0.0657758\n",
      "[10,  1000] RMSE: 0.0638021\n",
      "Total epoch 10 finished in 18.650895595550537 seconds with TRAINING RMSE loss: 0.06356689920786913\n",
      "Doing epoch 11 of 12\n",
      "[11,     0] RMSE: 0.0618703\n",
      "[11,  1000] RMSE: 0.0611544\n",
      "Total epoch 11 finished in 18.1252338886261 seconds with TRAINING RMSE loss: 0.06100115019464328\n",
      "Epoch 11 EVALUATION LOSS: 0.026179114228380738\n",
      "Saving model to model_save/model.epoch_11\n",
      "Saving model to model_save/model.last\n",
      "graph(%0 : Float(128, 4431)\n",
      "      %1 : Float(512, 4431)\n",
      "      %2 : Float(512, 512)\n",
      "      %3 : Float(1024, 512)\n",
      "      %4 : Float(512)\n",
      "      %5 : Float(512)\n",
      "      %6 : Float(1024)\n",
      "      %7 : Float(512, 1024)\n",
      "      %8 : Float(512, 512)\n",
      "      %9 : Float(4431, 512)\n",
      "      %10 : Float(512)\n",
      "      %11 : Float(512)\n",
      "      %12 : Float(4431)) {\n",
      "  %13 : Float(128, 512) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%0, %1, %4), scope: AutoEncoder\n",
      "  %14 : Float(128, 512) = onnx::Selu(%13), scope: AutoEncoder\n",
      "  %15 : Float(128, 512) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%14, %2, %5), scope: AutoEncoder\n",
      "  %16 : Float(128, 512) = onnx::Selu(%15), scope: AutoEncoder\n",
      "  %17 : Float(128, 1024) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%16, %3, %6), scope: AutoEncoder\n",
      "  %18 : Float(128, 1024) = onnx::Selu(%17), scope: AutoEncoder\n",
      "  %19 : Float(128, 1024), %20 : Dynamic = onnx::Dropout[is_test=1, ratio=0.8](%18), scope: AutoEncoder/Dropout[drop]\n",
      "  %21 : Float(128, 512) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%19, %7, %10), scope: AutoEncoder\n",
      "  %22 : Float(128, 512) = onnx::Selu(%21), scope: AutoEncoder\n",
      "  %23 : Float(128, 512) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%22, %8, %11), scope: AutoEncoder\n",
      "  %24 : Float(128, 512) = onnx::Selu(%23), scope: AutoEncoder\n",
      "  %25 : Float(128, 4431) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%24, %9, %12), scope: AutoEncoder\n",
      "  %26 : Float(128, 4431) = onnx::Selu(%25), scope: AutoEncoder\n",
      "  return (%26);\n",
      "}\n",
      "\n",
      "ONNX model saved to model_save/model.onnx!\n"
     ]
    }
   ],
   "source": [
    "!python run.py --gpu_ids 0 \\\n",
    "--path_to_train_data train \\\n",
    "--path_to_eval_data tests \\\n",
    "--hidden_layers 512,512,1024 \\\n",
    "--non_linearity_type selu \\\n",
    "--batch_size 128 \\\n",
    "--logdir model_save \\\n",
    "--drop_prob 0.8 \\\n",
    "--optimizer momentum \\\n",
    "--lr 0.005 \\\n",
    "--weight_decay 0 \\\n",
    "--aug_step 1 \\\n",
    "--noise_prob 0 \\\n",
    "--num_epochs 12 \\\n",
    "--summary_frequency 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "for index,row in df.iterrows():\n",
    "    if row[0] == 18951:\n",
    "        ind = index\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3891170"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = 3891170\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [userID, itemID, rating]\n",
       "Index: []"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf = pd.DataFrame(columns=['userID','itemID','rating'])\n",
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if(df.iloc[ind][0] == 18951):\n",
    "        tdf = tdf.append(df.iloc[ind])\n",
    "        ind+=1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = tdf.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.to_csv(\"test_18951.txt\", sep='\\t', index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(4434):\n",
    "    l.append([18951,i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf.to_csv(\"testdf_18951.txt\", sep='\\t', index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(constrained=False, drop_prob=0.8, hidden_layers='512,512,1024', non_linearity_type='selu', path_to_eval_data='tests', path_to_train_data='train', predictions_path='preds.txt', save_path='model_save/model.epoch_11', skip_last_layer_nl=False)\n",
      "GPU is available.\n",
      "Loading training data\n",
      "146644\n",
      "Data loaded\n",
      "Total items found: 146644\n",
      "Vector dim: 4431\n",
      "Loading eval data\n",
      "/home/ubuntu/DeepRecommender-master/reco_encoder/model/model.py:60: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  weight_init.xavier_uniform(w)\n",
      "/home/ubuntu/DeepRecommender-master/reco_encoder/model/model.py:72: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  weight_init.xavier_uniform(w)\n",
      "******************************\n",
      "******************************\n",
      "[4431, 512, 512, 1024]\n",
      "Dropout drop probability: 0.8\n",
      "Encoder pass:\n",
      "torch.Size([512, 4431])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([1024, 512])\n",
      "torch.Size([1024])\n",
      "Decoder pass:\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([4431, 512])\n",
      "torch.Size([4431])\n",
      "******************************\n",
      "******************************\n",
      "Loading model from: model_save/model.epoch_11\n",
      "######################################################\n",
      "######################################################\n",
      "############# AutoEncoder Model: #####################\n",
      "AutoEncoder(\n",
      "  (drop): Dropout(p=0.8)\n",
      "  (encode_w): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 512x4431]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 512x512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 1024x512]\n",
      "  )\n",
      "  (encode_b): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 512]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 1024]\n",
      "  )\n",
      "  (decode_w): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 512x1024]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 512x512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 4431x512]\n",
      "  )\n",
      "  (decode_b): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 512]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 512]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 4431]\n",
      "  )\n",
      ")\n",
      "######################################################\n",
      "######################################################\n",
      "Done: 0\n"
     ]
    }
   ],
   "source": [
    "!python infer.py \\\n",
    "--path_to_train_data train \\\n",
    "--path_to_eval_data tests \\\n",
    "--hidden_layers 512,512,1024 \\\n",
    "--non_linearity_type selu \\\n",
    "--save_path model_save/model.epoch_11 \\\n",
    "--drop_prob 0.8 \\\n",
    "--predictions_path preds.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv('preds.txt',delimiter='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18951</td>\n",
       "      <td>3582</td>\n",
       "      <td>1.026844</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18951</td>\n",
       "      <td>3906</td>\n",
       "      <td>1.018442</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18951</td>\n",
       "      <td>4025</td>\n",
       "      <td>0.995049</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18951</td>\n",
       "      <td>3164</td>\n",
       "      <td>1.012115</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18951</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.987053</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1         2    3\n",
       "0  18951  3582  1.026844  1.0\n",
       "1  18951  3906  1.018442  1.0\n",
       "2  18951  4025  0.995049  1.0\n",
       "3  18951  3164  1.012115  1.0\n",
       "4  18951  3328  0.987053  1.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.sort_values(1,inplace=True,ascending=False)\n",
    "tdf.sort_values('itemID',inplace=True,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0     1         2    3\n",
      "257  18951  4251  1.019388  1.0\n",
      "16   18951  4224  1.009129  1.0\n",
      "5    18951  4223  0.993901  1.0\n",
      "292  18951  4222  0.978424  1.0\n",
      "263  18951  4217  0.964515  1.0\n",
      "185  18951  4182  0.992785  1.0\n",
      "138  18951  4179  1.015135  1.0\n",
      "2    18951  4025  0.995049  1.0\n",
      "141  18951  4024  1.034578  1.0\n",
      "43   18951  3960  1.015859  1.0\n",
      "28   18951  3959  1.011680  1.0\n",
      "351  18951  3944  1.007758  1.0\n",
      "298  18951  3943  0.978963  1.0\n",
      "112  18951  3942  1.040879  1.0\n",
      "260  18951  3940  1.025038  1.0\n",
      "172  18951  3939  0.989226  1.0\n",
      "88   18951  3938  0.978047  1.0\n",
      "106  18951  3935  1.026593  1.0\n",
      "42   18951  3934  1.000157  1.0\n",
      "114  18951  3933  1.007156  1.0\n",
      "80   18951  3932  1.001165  1.0\n",
      "192  18951  3931  1.007964  1.0\n",
      "226  18951  3930  0.974374  1.0\n",
      "56   18951  3915  0.969437  1.0\n",
      "14   18951  3914  0.963195  1.0\n",
      "39   18951  3913  1.002358  1.0\n",
      "1    18951  3906  1.018442  1.0\n",
      "205  18951  3900  0.992872  1.0\n",
      "25   18951  3899  0.991758  1.0\n",
      "143  18951  3898  0.961280  1.0\n",
      "..     ...   ...       ...  ...\n",
      "122  18951  1280  1.001454  1.0\n",
      "354  18951  1256  0.998380  1.0\n",
      "134  18951  1254  1.048031  1.0\n",
      "190  18951  1245  1.011708  1.0\n",
      "332  18951  1207  0.990874  1.0\n",
      "259  18951  1139  0.991951  1.0\n",
      "222  18951  1117  1.058940  1.0\n",
      "245  18951  1116  1.061675  1.0\n",
      "280  18951  1049  0.991638  1.0\n",
      "187  18951  1013  0.982261  1.0\n",
      "295  18951  1006  1.012461  1.0\n",
      "248  18951   909  0.996001  1.0\n",
      "33   18951   907  1.042601  1.0\n",
      "150  18951   880  0.991214  1.0\n",
      "85   18951   873  0.999305  1.0\n",
      "84   18951   788  1.025451  1.0\n",
      "310  18951   786  0.997271  1.0\n",
      "274  18951   781  0.998910  1.0\n",
      "258  18951   751  1.032684  1.0\n",
      "345  18951   702  1.026972  1.0\n",
      "323  18951   657  0.983623  1.0\n",
      "220  18951   656  1.079021  1.0\n",
      "319  18951   395  0.975787  1.0\n",
      "244  18951   318  1.037138  1.0\n",
      "256  18951   317  1.080425  1.0\n",
      "347  18951   315  0.974322  1.0\n",
      "350  18951   250  0.990470  1.0\n",
      "355  18951   124  1.017662  1.0\n",
      "294  18951   123  1.017735  1.0\n",
      "96   18951    12  0.999160  1.0\n",
      "\n",
      "[358 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         userID  itemID  rating\n",
      "3891545   18951    4251       1\n",
      "3891544   18951    4224       1\n",
      "3891543   18951    4223       1\n",
      "3891542   18951    4222       1\n",
      "3891541   18951    4217       1\n",
      "3891540   18951    4182       1\n",
      "3891539   18951    4179       1\n",
      "3891538   18951    4111       0\n",
      "3891537   18951    4025       1\n",
      "3891536   18951    4024       1\n",
      "3891535   18951    3960       1\n",
      "3891534   18951    3959       1\n",
      "3891533   18951    3944       1\n",
      "3891532   18951    3943       1\n",
      "3891531   18951    3942       1\n",
      "3891530   18951    3940       1\n",
      "3891529   18951    3939       1\n",
      "3891528   18951    3938       1\n",
      "3891527   18951    3935       1\n",
      "3891526   18951    3934       1\n",
      "3891525   18951    3933       1\n",
      "3891524   18951    3932       1\n",
      "3891523   18951    3931       1\n",
      "3891522   18951    3930       1\n",
      "3891521   18951    3925       0\n",
      "3891520   18951    3917       0\n",
      "3891519   18951    3915       1\n",
      "3891518   18951    3914       1\n",
      "3891517   18951    3913       1\n",
      "3891516   18951    3906       1\n",
      "...         ...     ...     ...\n",
      "3891199   18951    1256       1\n",
      "3891198   18951    1254       1\n",
      "3891197   18951    1245       1\n",
      "3891196   18951    1207       1\n",
      "3891195   18951    1139       1\n",
      "3891194   18951    1117       1\n",
      "3891193   18951    1116       1\n",
      "3891192   18951    1049       1\n",
      "3891191   18951    1034       0\n",
      "3891190   18951    1013       1\n",
      "3891189   18951    1006       1\n",
      "3891188   18951     909       1\n",
      "3891187   18951     907       1\n",
      "3891186   18951     880       1\n",
      "3891185   18951     873       1\n",
      "3891184   18951     788       1\n",
      "3891183   18951     786       1\n",
      "3891182   18951     781       1\n",
      "3891181   18951     751       1\n",
      "3891180   18951     702       1\n",
      "3891179   18951     657       1\n",
      "3891178   18951     656       1\n",
      "3891177   18951     395       1\n",
      "3891176   18951     318       1\n",
      "3891175   18951     317       1\n",
      "3891174   18951     315       1\n",
      "3891173   18951     250       1\n",
      "3891172   18951     124       1\n",
      "3891171   18951     123       1\n",
      "3891170   18951      12       1\n",
      "\n",
      "[376 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
